{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions using the pre-trained ImageNet classifier\n",
    "\n",
    "There are two parts of an imagine classification network:\n",
    "\n",
    "The neural network begins witn a series of pooling and convolution layers, then ends with a densely connect classifier. The models in the `keras.applications` package ship with dense layer specialized towards performance against the ImageNet dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenetv2 import MobileNetV2\n",
    "\n",
    "\n",
    "conv_base = MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=True # include the densely connected classifer, which sits on top of hte convolutional network\n",
    ")\n",
    "\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipywebrtc import VideoStream, ImageRecorder\n",
    "from io import BytesIO\n",
    "from time import sleep\n",
    "from picamera import PiCamera\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from picamera.array import PiRGBArray\n",
    "\n",
    "from keras.applications.mobilenetv2 import preprocess_input, decode_predictions\n",
    "\n",
    "print('***')\n",
    "\n",
    "\n",
    "def extract_features(frame, frame_count=1, classifier_count=1000):\n",
    "    # expand 3D RGB frame into 4D \"batch\"\n",
    "    sample = np.expand_dims(frame, axis=0)\n",
    "    processed_sample = preprocess_input(sample.astype(np.float32))\n",
    "    print('expanded to 4D array')\n",
    "    features = conv_base.predict(processed_sample)\n",
    "    print('extracted features')\n",
    "    decoded_features = decode_predictions(features)\n",
    "    print('reshaped features')\n",
    "    print(decoded_features)\n",
    "    return decoded_features\n",
    "\n",
    "    \n",
    "                                   \n",
    "with PiCamera() as camera:\n",
    "    camera.resolution = (320, 240)\n",
    "    camera.framerate = 24\n",
    "    time.sleep(2)\n",
    "    # output = np.empty((224, 224, 3), dtype=np.float32)\n",
    "    print('initialized output')\n",
    "    # camera.capture(output, 'rgb')\n",
    "    ts = datetime.now()\n",
    "    camera.capture('data/{0}.jpg'.format((ts)))\n",
    "\n",
    "    \n",
    "    stream = PiRGBArray(camera, size=(320, 240))\n",
    "    camera.capture(stream, format='bgr')\n",
    "        # At this point the image is available as stream.array\n",
    "    frame = stream.array\n",
    "    frame = frame[0:224, 48:272, :]  # crop the frame\n",
    "\n",
    "    features = extract_features(frame)\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
